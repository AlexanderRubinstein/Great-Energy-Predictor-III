{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score\n",
    "\n",
    "\n",
    "random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "building_metadata = pd.read_csv('data' + os.sep + 'building_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv('data' + os.sep + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test = pd.read_csv('data' + os.sep + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_train = pd.read_csv('data' + os.sep + 'weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather_test = pd.read_csv('data' + os.sep + 'weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename timestamps columns\n",
    "# train.columns = ['building_id', 'meter', 'ti   mestamp_meter', 'meter_reading']\n",
    "# test.columns = ['row_id', 'building_id', 'meter', 'timestamp_meter']\n",
    "\n",
    "# weather_train.columns = ['site_id', 'timestamp_weather', 'air_temperature', 'cloud_coverage', 'dew_temperature', \\\n",
    "#                         'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']\n",
    "# weather_test.columns = ['site_id', 'timestamp_weather', 'air_temperature', 'cloud_coverage', 'dew_temperature', \\\n",
    "#                         'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = building_metadata.copy()\n",
    "# test_data = test_data.join(test.set_index('building_id'), on='building_id', how='inner')\n",
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9189</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      building_id  meter            timestamp  meter_reading  site_id  \\\n",
       "0               0      0  2016-01-01 00:00:00            0.0        0   \n",
       "2301            0      0  2016-01-01 01:00:00            0.0        0   \n",
       "4594            0      0  2016-01-01 02:00:00            0.0        0   \n",
       "6893            0      0  2016-01-01 03:00:00            0.0        0   \n",
       "9189            0      0  2016-01-01 04:00:00            0.0        0   \n",
       "\n",
       "     primary_use  square_feet  year_built  floor_count  \n",
       "0      Education         7432      2008.0          NaN  \n",
       "2301   Education         7432      2008.0          NaN  \n",
       "4594   Education         7432      2008.0          NaN  \n",
       "6893   Education         7432      2008.0          NaN  \n",
       "9189   Education         7432      2008.0          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_data = train_data.join(building_metadata.set_index('building_id'), on='building_id', how='inner')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20216100, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_electricity = train_data[train_data['meter'] == 0]\n",
    "#train_data_chilledWater = train_data[train_data['meter'] == 1]\n",
    "train_data_steam = train_data[train_data['meter'] == 2]\n",
    "#train_data_hotWater = train_data[train_data['meter'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertDate(train_data):\n",
    "    # Convert date to datetime format\n",
    "    train_data['timestamp'] = pd.to_datetime(train_data['timestamp'])\n",
    "    \n",
    "    # Extract and store year, month, day, hour\n",
    "    train_data['year'] = train_data.loc[:,'timestamp'].dt.year\n",
    "    train_data['month'] = train_data.loc[:,'timestamp'].dt.month\n",
    "    train_data['day'] = train_data.loc[:,'timestamp'].dt.day\n",
    "    train_data['hour'] = train_data.loc[:,'timestamp'].dt.hour\n",
    "    \n",
    "    train_data.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "#ConvertDate(train_data_electricity)\n",
    "#ConvertDate(train_data_chilledWater)\n",
    "ConvertDate(train_data_steam)\n",
    "#ConvertDate(train_data_hotWater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMeanMeterReading(train_data, buildings_number):\n",
    "    new_columns = list(train_data.columns)\n",
    "    new_columns.append('meter_reading_mean')\n",
    "\n",
    "    train = pd.DataFrame(columns=new_columns)\n",
    "\n",
    "    building_ids = train_data['building_id'].unique()[1:buildings_number]\n",
    "    train_data_cutted = train_data[train_data['building_id'] == train_data['building_id'].unique()[0]]\n",
    "    for building_id in building_ids:\n",
    "        train_data_cutted = train_data_cutted.append(train_data[train_data['building_id'] == building_id], ignore_index=True)\n",
    "    \n",
    "    for building_id in train_data_cutted['building_id'].unique():\n",
    "        buildingID = train_data_cutted[train_data_cutted['building_id'] == building_id]\n",
    "        for month_id in buildingID['month'].unique():\n",
    "            buildingIDmonthID = buildingID[buildingID['month'] == month_id]\n",
    "            for day_id in buildingIDmonthID['day'].unique():\n",
    "                buildingIDmonthIDdayID = buildingIDmonthID[buildingIDmonthID['day'] == day_id]\n",
    "                train = train.append(buildingIDmonthIDdayID[0:1], ignore_index=True)\n",
    "                train.set_value(train.shape[0]-1, 'meter_reading_mean', buildingIDmonthIDdayID['meter_reading'].mean())\n",
    "    \n",
    "    train = train.drop(['hour', 'year', 'building_id', 'floor_count', 'meter_reading', 'meter'], axis=1)\n",
    "    train['primary_use'] = LabelEncoder().fit_transform(train['primary_use'])\n",
    "    train = train.apply(pd.to_numeric)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "#train_electricity = CreateMeanMeterReading(train_data_electricity, 10)\n",
    "#train_chilledWater = CreateMeanMeterReading(train_data_chilledWater, 10)\n",
    "train_steam = CreateMeanMeterReading(train_data_steam, 10)\n",
    "#train_hotWater = CreateMeanMeterReading(train_data_hotWater, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_steam['meter_reading_mean']\n",
    "train_steam.drop(['meter_reading_mean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steam['year_built'].fillna('2016', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(model):\n",
    "    numeric_features = ['day', 'month', 'square_feet', 'year_built']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_features = ['site_id', 'primary_use']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', model)])\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def manual_split(X, y, train_size=0.8):\n",
    "    X_train, X_valid = X[:int(train_size*X.shape[0])], X[int(train_size*X.shape[0]):]\n",
    "    y_train, y_valid = y[:int(train_size*X.shape[0])], y[int(train_size*X.shape[0]):]\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def run_grid_search(X, y, model, param_grid):\n",
    "    pipe = make_pipeline(model)\n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X, y)\n",
    "    print(\"Best parameter (CV score=%0.3f):\" % grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    return grid_search\n",
    "\n",
    "def full_procedure(X_train, X_test, y_train, model, param_grid, with_grid_search=False):\n",
    "    if with_grid_search:\n",
    "        grid_search = run_grid_search(X_train, y_train, model, param_grid)\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        y_pred[y_pred<0] = 0\n",
    "    else:\n",
    "        pipe = make_pipeline(model=model)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        y_pred[y_pred<0] = 0\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3505371208604529\n",
      "Best parameter (CV score=-13.392):\n",
      "{'regressor__alpha': 100000.0}\n",
      "-2.269903964240811e+31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = manual_split(train_steam, target)\n",
    "param_grid_linear = {'regressor__alpha': np.logspace(5, 8, 7)}\n",
    "\n",
    "y_pred = full_procedure(X_train, X_test, y_train, Lasso(), param_grid_linear)\n",
    "print(r2_score(y_pred, y_test))\n",
    "\n",
    "y_pred = full_procedure(X_train, X_test, y_train, Lasso(), param_grid_linear, with_grid_search=True)\n",
    "print(r2_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=-13.392):\n",
      "{'regressor__alpha': 100000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=-13.393):\n",
      "{'regressor__alpha': 100000000.0}\n",
      "Best parameter (CV score=-47.763):\n",
      "{'regressor__bootstrap': True, 'regressor__max_depth': 80, 'regressor__max_features': 3, 'regressor__min_samples_leaf': 5, 'regressor__min_samples_split': 12, 'regressor__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# gridsearching parameters\n",
    "param_grid_linear = {'regressor__alpha': np.logspace(5, 8, 7)}\n",
    "param_grid_forest = {\n",
    "    'regressor__bootstrap': [True],\n",
    "    'regressor__max_depth': [80, 90, 100, 110],\n",
    "    'regressor__max_features': [2, 3],\n",
    "    'regressor__min_samples_leaf': [3, 4, 5],\n",
    "    'regressor__min_samples_split': [8, 10, 12],\n",
    "    'regressor__n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "models = [Lasso(random_state=random_state), Ridge(random_state=random_state), \n",
    "          RandomForestRegressor(random_state=random_state)]\n",
    "grid_search_results = []\n",
    "for i, model in enumerate(models):\n",
    "    if(i<2):\n",
    "        param_grid = param_grid_linear\n",
    "    else:\n",
    "        param_grid = param_grid_forest\n",
    "    grid_search = run_grid_search(X_train, y_train, model, param_grid=param_grid)\n",
    "    grid_search_results.append(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it's the best that we could have done for LinearRegression(). But for 3 other models there is still some place for improvement. Let's tune hyperparameters for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) score: -8.846\n",
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) score: -8.887\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=1, solver='auto', tol=0.001) score: -8.851\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
      "                      oob_score=False, random_state=1, verbose=0,\n",
      "                      warm_start=False) score: -0.254\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = manual_split(train_steam, target, train_size=0.8)\n",
    "\n",
    "#dummy models run\n",
    "models = [LinearRegression(), Lasso(random_state=random_state), Ridge(random_state=random_state), \n",
    "          RandomForestRegressor(random_state=random_state, n_estimators=100, n_jobs=-1)]\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model, \"score: %.3f\" % r2_score(model.predict(X_valid), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "      normalize=False, positive=False, precompute=False, random_state=1,\n",
      "      selection='cyclic', tol=0.0001, warm_start=False) score: -1.351\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=1, solver='auto', tol=0.001) score: -1.331\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                      warm_start=False) score: -0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#applying feature transformations\n",
    "models = [Lasso(random_state=random_state), Ridge(random_state=random_state), \n",
    "          RandomForestRegressor(random_state=random_state)]\n",
    "\n",
    "for model in models:\n",
    "    pipe = make_pipeline(model=model)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_valid)\n",
    "    y_pred[y_pred<0] = 0\n",
    "    print(model, \"score: %.3f\" % r2_score(y_pred, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
